{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuhjNPTpju5n"
   },
   "source": [
    "# Gemini embeddings demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddZb9-z46mM5"
   },
   "source": [
    "## What is text embedding\n",
    "\n",
    "A list of floating point numbers that represent the meaning of a word, sentence, or paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YD6urJjWGVDf"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJriBaWmkL6Z"
   },
   "source": [
    "## Setup API key\n",
    "Store your Google API key in .env under current folder:\n",
    "GOOGLE_API_KEY=xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zey3UiYGDDzU"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGpQ8Eg0kNXW"
   },
   "source": [
    "## Embed content\n",
    "- model: `models/text-embedding-004`\n",
    "- embed call: `embed_content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J76TNa3QDwCc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03669632, -0.029696692, -0.01009818, -0.016267 ... TRIMMED]\n"
     ]
    }
   ],
   "source": [
    "text = \"Happy everyday!\"\n",
    "result = genai.embed_content(model=\"models/text-embedding-004\", content=text)\n",
    "\n",
    "# Print just a part of the embedding to keep the output manageable\n",
    "print(str(result['embedding'])[:50], '... TRIMMED]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rU6XX33547Ll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(result['embedding'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUKqxF9yQuZl"
   },
   "source": [
    "## Batch embed content\n",
    "\n",
    "embed a list of multiple prompts with one API call for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Hzz-7Heuf4tV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.028737506, 0.049994964, -0.02702591, -0.059048 ... TRIMMED]\n",
      "[0.04651278, 0.01845331, 0.029534813, 0.01420539,  ... TRIMMED]\n",
      "[-0.011723411, 0.009849717, -0.020808367, -0.00312 ... TRIMMED]\n"
     ]
    }
   ],
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=[\n",
    "      'What is genAI?',\n",
    "      'What is your dinner plan?',\n",
    "      'How does Zumba work for your body?'])\n",
    "\n",
    "for embedding in result['embedding']:\n",
    "  print(str(embedding)[:50], '... TRIMMED]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0r0dt958QQg"
   },
   "source": [
    "## Truncating embeddings\n",
    "\n",
    "Use `output_dimensionality` to truncate the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bX_AjfMx8PvV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not truncated\n",
    "result1 = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"Postive thinking is key!\")\n",
    "\n",
    "\n",
    "# Truncated\n",
    "result2 = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"Postive thinking is key!\",\n",
    "    output_dimensionality=10)\n",
    "\n",
    "\n",
    "(len(result1['embedding']), len(result2['embedding']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSKcLGIpo8yc"
   },
   "source": [
    "## Specify `task_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz0zq1_shk98"
   },
   "source": [
    "There are 5 parameters for the `embed_content` method: \n",
    "\n",
    "* `model`: Required. Must be `models/text-embedding-004` or `models/embedding-001`.\n",
    "* `content`: Required. The content that you would like to embed.\n",
    "* `task_type`: Optional. The task type for which the embeddings will be used.\n",
    "* `title`: Optional. You should only set this parameter if your task type is `retrieval_document` (or `document`).\n",
    "* `output_dimensionality`: Optional. Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. This is supported by `models/text-embedding-004`, but cannot be specified in `models/embedding-001`.\n",
    "\n",
    "The following task_type parameters are accepted:\n",
    "\n",
    "* `unspecified`: default to `retrieval_query`\n",
    "* `retrieval_query` (or `query`): The given text is a query in a search/retrieval setting\n",
    "* `retrieval_document` (or `document`): The given text is a document, Optionally, also set the `title` parameter with the title of the document\n",
    "* `semantic_similarity` (or `similarity`): The given text will be used for Semantic Textual Similarity (STS)\n",
    "* `classification`: The given text will be classified\n",
    "* `clustering`: The embeddings used for clustering\n",
    "* `question_answering`: The given text used for question answering\n",
    "* `fact_verification`: The given text used for fact verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LFjMapMV91es"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.028295688, -0.06549204, -0.004657541, -0.058933 ... TRIMMED]\n",
      "[0.02249292, -0.03873647, -0.014411285, -0.0554903 ... TRIMMED]\n"
     ]
    }
   ],
   "source": [
    "# Notice the API returns different embeddings depending on `task_type`\n",
    "result1 = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"Postive thinking is key!\")\n",
    "\n",
    "result2 = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"Postive thinking is key!\",\n",
    "    task_type=\"document\")\n",
    "\n",
    "print(str(result1['embedding'])[:50], '... TRIMMED]')\n",
    "print(str(result2['embedding'])[:50], '... TRIMMED]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpBm7GIdbkdK"
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* [Search Reranking](https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb): Use embeddings from the Gemini API to rerank search results from Wikipedia.\n",
    "\n",
    "* [Anomaly detection with embeddings](https://github.com/google-gemini/cookbook/blob/main/examples/Anomaly_detection_with_embeddings.ipynb): Use embeddings from the Gemini API to detect potential outliers in your dataset.\n",
    "\n",
    "* [Train a text classifier](https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb): Use embeddings from the Gemini API to train a model that can classify different types of newsgroup posts based on the topic\n",
    "\n",
    "* [Example with Chroma DB](https://github.com/google/generative-ai-docs/blob/main/examples/gemini/python/vectordb_with_chroma/vectordb_with_chroma.ipynb) Embeddings with Vector Databases\n",
    "\n",
    "* [Embeddings guide](https://ai.google.dev/docs/embeddings_guide)  general embedding guide\n",
    "\n",
    "* [Gemini API SDK](https://ai.google.dev/tutorials/python_quickstart#use_embeddings)\n",
    "\n",
    "* [API reference embedContent](https://ai.google.dev/api/rest/v1/models/embedContent) and [batchEmbedContents](https://ai.google.dev/api/rest/v1/models/batchEmbedContents)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Embeddings.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
