{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f22a409c18ef"
   },
   "source": [
    "# Summarization using Gemini + Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f892e8b2c8ef"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[Gemini](https://ai.google.dev/models/gemini) - family of generative AI models used to generate content and solve problems; used to handle both text and images as input.\n",
    "\n",
    "[LangChain](https://www.langchain.com/) - data framework to integrate with Large Language Models (LLM) like Gemini easier for applications.\n",
    "\n",
    "Here is demo how to create an application to summarize large documents using the Gemini API and LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHj4T7hsx1EB"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-49oubeWCHfO"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet langchain-core\n",
    "!pip install --quiet langchain\n",
    "!pip install --quiet langchain-google-genai\n",
    "!pip install --quiet -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAv0UicpKARZ"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQOGMejVu-6D"
   },
   "source": [
    "## Setup API key\n",
    "\n",
    "Place below line to .env under current folder, \n",
    "\n",
    "GOOGLE_API_KEY=xxx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ysayz8skEfBW"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7wgsoiz418u"
   },
   "source": [
    "## Summarize text\n",
    "\n",
    "Perform the following steps:\n",
    "1. Read and parse the website data using LangChain.\n",
    "2. Chain together the following:\n",
    "    * A prompt for extracting the required input data from the parsed website data.\n",
    "    * A prompt for summarizing the text using LangChain.\n",
    "    * An LLM model (such as the Gemini model) for prompting.\n",
    "3. Run the created chain to prompt the model for the summary of the website data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tKpRvmMRX23"
   },
   "source": [
    "### Read and parse the website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TTgmyxXzKCSq"
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://dreamcloud.artark.ca/build-k8s-cluster-on-hyper-v/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xlf_F_4B6lB"
   },
   "source": [
    "### Initialize the Gemini model\n",
    "\n",
    "Use Gemini 1.5 Flash, (`gemini-1.5-flash-latest`), as it supports text summarization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WWA9F0ZqB-8k"
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TECDzaUSTvS"
   },
   "source": [
    "### Create prompt templates\n",
    "\n",
    "Use LangChain's [`PromptTemplate`](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/) to generate prompts for summarizing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rixvvvaNKLe_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] template='Write a concise summary of the following:\\n\"{text}\"\\nCONCISE SUMMARY:'\n"
     ]
    }
   ],
   "source": [
    "# To extract data from WebBaseLoader\n",
    "doc_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
    "\n",
    "# To query Gemini\n",
    "llm_prompt_template = \"\"\"Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "llm_prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "print(llm_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wPBMFyISh13"
   },
   "source": [
    "### Create a Stuff documents chain\n",
    "\n",
    "LangChain provides [Chains](https://python.langchain.com/docs/modules/chains/) for chaining together LLMs with each other or other components for complex applications, create a **Stuff documents chain** to combine all the documents, insert them into the prompt and pass that prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EMZomQdyKMr5"
   },
   "outputs": [],
   "source": [
    "stuff_chain = (\n",
    "    # Extract data from the documents and add to the key `text`.\n",
    "    {\n",
    "        \"text\": lambda docs: \"\\n\\n\".join(\n",
    "            format_document(doc, doc_prompt) for doc in docs\n",
    "        )\n",
    "    }\n",
    "    | llm_prompt         # Prompt for Gemini\n",
    "    | llm                # Gemini API function\n",
    "    | StrOutputParser()  # output parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L0Tvk_5eQzC"
   },
   "source": [
    "### Prompt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "k9_GxkA5ePRR"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> This article provides a comprehensive guide on building a Kubernetes cluster on Hyper-V using Vagrant. It addresses the challenges of setting up static IP addresses for Hyper-V VMs and configuring networks, offering solutions using PowerShell scripts and Vagrantfile modifications. \n",
       "> \n",
       "> The author demonstrates how to create a 2-node Kubernetes cluster with static IPs, install Docker and Kubernetes, and automate the process using Vagrant. They also introduce a set of scripts for setting up Kubernetes clusters on various platforms, including physical Linux, Linux VMs, and WSL2. \n",
       "> \n",
       "> The article concludes by highlighting the benefits of using this method for local Kubernetes lab environments for testing and educational purposes. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(stuff_chain.invoke(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfrBsxUFgZzc"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this demo, we've explored how to use Gemini and LangChain to build an application for summarizing large documents. The process involved reading and parsing website data, creating a chain of prompts and models, and using the Gemini API to generate concise summaries. The combination of Gemini's generative AI capabilities with LangChain's framework simplifies the integration and handling of complex data, making it easier to extract meaningful insights from extensive text sources.\n",
    "\n",
    "This approach is particularly useful for efficiently condensing large amounts of information into concise summaries, aiding in quick comprehension and decision-making. Whether for research, business, or educational purposes, the techniques demonstrated here provide a powerful toolset for leveraging AI to streamline information processing and enhance content accessibility.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Gemini_LangChain_Summarization_WebLoad.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
