{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unleash the Power of RAG - Building Intelligent Apps with Chroma and Gemini Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The field of Generative AI (GenAI) is rapidly evolving, offering exciting possibilities for applications that interact with and understand human language. One promising approach is Retriever-Augmented Generation (RAG), which combines information retrieval with powerful language models. This blog delves into building a RAG application using Chroma, a vector database, and Gemini Pro, a state-of-the-art large language model from Google.\n",
    "\n",
    "**Chroma: The Key to Efficient Information Retrieval**\n",
    "\n",
    "Chroma serves as the foundation for our RAG application. It's a vector database designed specifically for storing and retrieving vast amounts of data represented as numerical vectors or embeddings. These embeddings capture the semantic meaning of text, enabling Chroma to perform rapid searches based on similarity, rather than exact keyword matches.\n",
    "\n",
    "**Why Chroma is Crucial for GenAI Applications**\n",
    "\n",
    "GenAI applications, like chatbots, question-answering systems, and recommendation engines, rely heavily on processing and understanding information quickly and accurately. Chroma plays a critical role in this process by offering several advantages:\n",
    "\n",
    "- Efficient Information Retrieval: Chroma's vector-based search allows for rapid retrieval of relevant information based on semantic similarity. This is crucial for providing accurate and contextually relevant responses.\n",
    "- Knowledge Base Management: GenAI models often require access to a large knowledge base. Chroma can efficiently store and manage this knowledge, making it readily available for the model to access.\n",
    "- Real-time Performance: Chroma is optimized for speed, enabling real-time interactions with users. This is essential for applications that require immediate responses, such as chatbots or virtual assistants.\n",
    "- Scalability: As the amount of data grows, Chroma can scale to handle increasing workloads, ensuring the continued performance of the GenAI application.\n",
    "\n",
    "In essence, Chroma empowers GenAI applications to deliver exceptional performance and user experiences by effectively managing and accessing information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a RAG App with Gemini Pro API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get hands-on and build a RAG application using Chroma and Gemini Pro. We'll cover the installation process, explore code examples, and see how these tools work together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q google-generativeai   \n",
    "!pip install -q chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup API key**\n",
    "Put Gemini API key in .env under current folder,\n",
    "```\n",
    "GOOGLE_API_KEY=xxx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list supported embedding models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'embedContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample data**\n",
    "\n",
    "We use documents list to hold reference document, each item is a string, represents one short text document or chunk of long text document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gemini is the result of large-scale collaborative efforts by teams across Google, including our colleagues at Google Research. It was built from the ground up to be multimodal, which means it can generalize and seamlessly understand, operate across and combine different types of information including text, code, audio, image and video.',\n",
       " 'We designed Gemini to be natively multimodal, pre-trained from the start on different modalities. Then we fine-tuned it with additional multimodal data to further refine its effectiveness. This helps Gemini seamlessly understand and reason about all kinds of inputs from the ground up, far better than existing multimodal models — and its capabilities are state of the art in nearly every domain.',\n",
       " 'Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. We’ve conducted novel research into potential risk areas like cyber-offense, persuasion and autonomy, and have applied Google Research’s best-in-class adversarial testing techniques to help identify critical safety issues in advance of Gemini’s deployment.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOCUMENT1 = \"Gemini is the result of large-scale collaborative efforts by teams across Google, including our colleagues at Google Research. It was built from the ground up to be multimodal, which means it can generalize and seamlessly understand, operate across and combine different types of information including text, code, audio, image and video.\"\n",
    "DOCUMENT2 = \"We designed Gemini to be natively multimodal, pre-trained from the start on different modalities. Then we fine-tuned it with additional multimodal data to further refine its effectiveness. This helps Gemini seamlessly understand and reason about all kinds of inputs from the ground up, far better than existing multimodal models — and its capabilities are state of the art in nearly every domain.\"\n",
    "DOCUMENT3 = \"Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. We’ve conducted novel research into potential risk areas like cyber-offense, persuasion and autonomy, and have applied Google Research’s best-in-class adversarial testing techniques to help identify critical safety issues in advance of Gemini’s deployment.\"\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings with model embedding-001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "  def __call__(self, input: Documents) -> Embeddings:\n",
    "    model = 'models/embedding-001'\n",
    "    title = \"Custom query\"\n",
    "    return genai.embed_content(model=model,\n",
    "                                content=input,\n",
    "                                task_type=\"retrieval_document\",\n",
    "                                title=title)[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a custom class named `GeminiEmbeddingFunction` that implements the `EmbeddingFunction` interface. This class is designed to interact with the Gemini language model to generate embeddings for text documents.\n",
    "\n",
    "1. **Class Definition:**\n",
    "\n",
    "   - `GeminiEmbeddingFunction(EmbeddingFunction)`: This line declares the class `GeminiEmbeddingFunction` and indicates that it inherits from the `EmbeddingFunction` class. This means it must implement the `__call__` method.\n",
    "\n",
    "2. **`__call__` Method:**\n",
    "\n",
    "   - `def __call__(self, input: Documents) -> Embeddings`: This is the method that is called when an instance of the class is used as a function. It takes an `input` parameter of type `Documents` (which is presumably a data structure representing a list of documents) and returns an `Embeddings` object.\n",
    "\n",
    "3. **Model Selection:**\n",
    "\n",
    "   - `model = 'models/embedding-001'`: This line sets the `model` variable to the string 'models/embedding-001'. This likely refers to a specific embedding model within the Gemini language model framework.\n",
    "\n",
    "4. **Title Setting:**\n",
    "\n",
    "   - `title = \"Custom query\"`: This line sets the `title` variable to the string \"Custom query\". This might be used as a metadata field for the embedding.\n",
    "\n",
    "5. **Embedding Generation:**\n",
    "\n",
    "   - `return genai.embed_content(model=model, content=input, task_type=\"retrieval_document\", title=title)[\"embedding\"]`: This line calls the `genai.embed_content` function from the `genai` module. It passes the following arguments:\n",
    "     - `model`: The selected embedding model ('models/embedding-001').\n",
    "     - `content`: The input documents to be embedded.\n",
    "     - `task_type`: Specifies the task for which the embeddings are being generated. In this case, it's set to \"retrieval_document\", indicating that the embeddings will be used for document retrieval.\n",
    "     - `title`: The custom title for the embedding.\n",
    "   - The function returns a dictionary containing the embeddings and other metadata. The code extracts the 'embedding' key from this dictionary and returns it as the result of the `__call__` method.\n",
    "\n",
    "We define a function that can be used to generate embeddings for a list of documents using the Gemini language model. The embeddings can then be used for various tasks, such as semantic search or document similarity calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create chroma db**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chroma_db(documents, name, embedding_function=GeminiEmbeddingFunction()):\n",
    "    \"\"\"\n",
    "    Creates a ChromaDB collection, generates embeddings for the documents using the provided embedding function, and adds the documents and embeddings to the collection.\n",
    "\n",
    "    Args:\n",
    "        documents (list): A list of documents to be added to the collection.\n",
    "        name (str): The name of the collection.\n",
    "        embedding_function (EmbeddingFunction, optional): The function used to generate embeddings for the documents. Defaults to GeminiEmbeddingFunction().\n",
    "\n",
    "    Returns:\n",
    "        chromadb.Collection: The created ChromaDB collection.\n",
    "    \"\"\"\n",
    "\n",
    "    chroma_client = chromadb.Client()\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = embedding_function(documents)\n",
    "    print(\"Embeddings generated:\", embeddings)\n",
    "\n",
    "    # Verify data types\n",
    "    if not isinstance(embeddings, list) or not all(isinstance(embedding, list) for embedding in embeddings):\n",
    "        raise ValueError(\"Embeddings must be a list of lists of numbers.\")\n",
    "\n",
    "    if not all(isinstance(value, (int, float)) for embedding in embeddings for value in embedding):\n",
    "        raise ValueError(\"Embedding elements must be numerical.\")\n",
    "\n",
    "    # Add documents and embeddings\n",
    "    try:\n",
    "        db.add(\n",
    "            documents=documents,\n",
    "            embeddings=embeddings,\n",
    "            ids=[str(i) for i in range(len(documents))]\n",
    "        )\n",
    "        print(\"Documents and embeddings added successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding documents and embeddings: {e}\")\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_chroma_db` function creates a ChromaDB collection, generates embeddings for a list of documents using a specified embedding function, and adds both the documents and their corresponding embeddings to the collection.\n",
    "\n",
    "1. **Function Definition:**\n",
    "   - `def create_chroma_db(documents, name, embedding_function=GeminiEmbeddingFunction())`:\n",
    "     - Defines a function named `create_chroma_db` that takes three arguments:\n",
    "       - `documents`: A list of documents to be added to the collection.\n",
    "       - `name`: The name to be given to the ChromaDB collection.\n",
    "       - `embedding_function`: An optional argument specifying the function used to generate embeddings for the documents. If not provided, `GeminiEmbeddingFunction()` is used by default.\n",
    "\n",
    "2. **ChromaDB Client and Collection Creation:**\n",
    "   - `chroma_client = chromadb.Client()`: Creates an instance of the ChromaDB client.\n",
    "   - `db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())`: Creates a new collection in the ChromaDB database with the specified `name` and uses the provided `embedding_function` to generate embeddings for the documents.\n",
    "\n",
    "3. **Embedding Generation:**\n",
    "   - `embeddings = embedding_function(documents)`: Calls the provided `embedding_function` on the `documents` list to generate embeddings for each document.\n",
    "\n",
    "4. **Data Type Validation:**\n",
    "   - `if not isinstance(embeddings, list) or not all(isinstance(embedding, list) for embedding in embeddings):`: Checks if the `embeddings` are a list of lists.\n",
    "   - `if not all(isinstance(value, (int, float)) for embedding in embeddings for value in embedding):`: Checks if all elements within the embeddings are numerical (integers or floats).\n",
    "\n",
    "5. **Document and Embedding Addition:**\n",
    "   - `db.add(documents=documents, embeddings=embeddings, ids=[str(i) for i in range(len(documents))])`: Adds the documents and their corresponding embeddings to the ChromaDB collection. Unique identifiers are generated using a list comprehension for each document.\n",
    "\n",
    "6. **Error Handling:**\n",
    "   - A `try-except` block is used to catch any exceptions that might occur during the process of adding documents and embeddings to the collection.\n",
    "\n",
    "7. **Collection Return:**\n",
    "   - The newly created ChromaDB collection is returned.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- The function ensures that the embeddings are generated using the specified `embedding_function`.\n",
    "- It validates the data types of the embeddings to ensure they are compatible with ChromaDB.\n",
    "- It adds both the documents and their embeddings to the collection, using unique identifiers for each document.\n",
    "- It includes error handling to catch potential exceptions during the process.\n",
    "\n",
    "This function provides a robust and flexible way to create ChromaDB collections with custom embedding functions and data validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup vector db**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list and clean up old db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=geminidb)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(name=\"geminidb\")\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_chroma_db(documents, \"geminidb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify db**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find embeddings is None from db.get(). When using get or query you can use the include parameter to specify which data you want returned - any of embeddings, documents, metadatas, and for query, distances. By default, Chroma will return the documents, metadatas and in the case of query, the distances of the results. embeddings are excluded by default for performance and the ids are always returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get(include=['embeddings', 'documents', 'metadatas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.get(include=['embeddings', 'documents', 'metadatas'])['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadatas</th>\n",
       "      <th>documents</th>\n",
       "      <th>uris</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.04447142407298088, -0.052165351808071136, -...</td>\n",
       "      <td>None</td>\n",
       "      <td>Gemini is the result of large-scale collaborat...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.05980474501848221, -0.05400879308581352, -0...</td>\n",
       "      <td>None</td>\n",
       "      <td>We designed Gemini to be natively multimodal, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.017100121825933456, -0.06025487929582596, -...</td>\n",
       "      <td>None</td>\n",
       "      <td>Gemini has the most comprehensive safety evalu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ids                                         embeddings metadatas  \\\n",
       "0   0  [0.04447142407298088, -0.052165351808071136, -...      None   \n",
       "1   1  [0.05980474501848221, -0.05400879308581352, -0...      None   \n",
       "2   2  [0.017100121825933456, -0.06025487929582596, -...      None   \n",
       "\n",
       "                                           documents  uris  data  \n",
       "0  Gemini is the result of large-scale collaborat...  None  None  \n",
       "1  We designed Gemini to be natively multimodal, ...  None  None  \n",
       "2  Gemini has the most comprehensive safety evalu...  None  None  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(db.peek(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the relevant document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query, db):\n",
    "  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n",
    "  return passage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform embedding search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. We’ve conducted novel research into potential risk areas like cyber-offense, persuasion and autonomy, and have applied Google Research’s best-in-class adversarial testing techniques to help identify critical safety issues in advance of Gemini’s deployment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage = get_relevant_passage(\"safety\", db)\n",
    "Markdown(passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
    "  prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
    "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
    "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
    "  strike a friendly and converstional tone. \\\n",
    "  If the passage is irrelevant to the answer, you may ignore it.\n",
    "  QUESTION: '{query}'\n",
    "  PASSAGE: '{relevant_passage}'\n",
    "\n",
    "    ANSWER:\n",
    "  \"\"\").format(query=query, relevant_passage=escaped)\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pass a query to the prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a helpful and informative bot that answers questions using text from the reference passage included below.   Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.   However, you are talking to a non-technical audience, so be sure to break down complicated concepts and   strike a friendly and converstional tone.   If the passage is irrelevant to the answer, you may ignore it.\n",
       "  QUESTION: 'what is safety evaluations for gemini?'\n",
       "  PASSAGE: 'Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. We’ve conducted novel research into potential risk areas like cyber-offense, persuasion and autonomy, and have applied Google Research’s best-in-class adversarial testing techniques to help identify critical safety issues in advance of Gemini’s deployment.'\n",
       "\n",
       "    ANSWER:\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is safety evaluations for gemini?\"\n",
    "prompt = make_prompt(query, passage)\n",
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Google has performed the most comprehensive safety evaluations yet for Gemini, including assessments for bias and toxicity. Google uses advanced methods, including adversarial testing, to help identify possible safety issues before Gemini is released."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This blog has demonstrated how Chroma and Gemini Pro can be combined to create a powerful RAG application. By leveraging Chroma's efficient information retrieval capabilities and Gemini Pro's advanced language understanding, we can build intelligent applications that can answer questions, generate creative text formats, and provide informative summaries. As GenAI technology continues to evolve, the potential for building even more sophisticated and user-friendly applications becomes increasingly exciting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
